kube-prometheus-stack:

  grafana:
    enabled: true
    adminPassword: crisp_123
    defaultDashboardsEnabled: false
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        folderAnnotation: "grafana_folder"
        searchNamespaces: monitoring
        provider:
          folderFromFilesStructure: true
      datasources:
        enabled: true
        defaultDatasourceEnabled: false
        label: grafana_datasource
      alerts:
        enabled: true
        label: grafanaalert
      plugins:
        enabled: true
        label: grafana_plugin
    plugins: [""]
    persistence:
      type: pvc
      enabled: false
      # storageClassName: *crisp_storageClass
      accessModes:
        - ReadWriteOnce
      size: 5Gi
    extraConfigmapMounts:
      - name: grafana-dashboards-permissions
        configMap: prometheus-mgmt-grafana-dashboards-permissions
        mountPath: /etc/grafana/provisioning/permissions
      # - name: grafana-folders
      #   configMap: grafana-folders
      #   mountPath: /etc/grafana/provisioning/folders

    nodeSelector:
      kubernetes.io/os: linux
      ReservedFor: monitoring

    tolerations:
      - key: "CriticalAddonsOnly"
        operator: "Equal"
        value: "true"
      - key: "ForMonitoring"
        operator: "Equal"
        value: "true"

    alerting:
      #cluster-rules.yaml: 
      #  a: "{{ .Files.Get "alerting/clusters/cluster-rules.yaml"  }}"
      #  file: alerting/team2/rules.yaml
      #team3-alert-rules.yaml:
      #  file: alerting/team3/rules.yaml
      notification-policies.yaml:
        apiVersion: 1
        policies:
        - orgId: 1
          receiver: DevOps
          group_by:
          - grafana_folder
          - alertname
          routes:
            - receiver: DevOps
              object_matchers:
              - ['team', '=', 'DevOps']
      contactpoints.yaml:
        apiVersion: 1
        contactPoints:
          - orgId: 1
            name: DevOps
            receivers:
              - uid: msteams-receiver
                type: webhook
                settings:
                  url: "http://prometheus-msteams:2000/tcmalerts"
                  # We need to escape double curly braces for the tpl function.
                  # message: '{{ `{{ template "default.message" . }}` }}'
                  # title: '{{ `{{ template "default.title" . }}` }}'
                  httpMethod: "POST"
                  autoResolve: true
                  disableResolveMessage: true

    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
      paths:
        - "/"
      hosts:
        - grafana.mgmt.crisp.rbro.rbg.cc
      tls:
        - hosts:
            - grafana.mgmt.crisp.rbro.rbg.cc
          secretName: grafana.mgmt.crisp.rbro.rbg.cc
    additionalDataSources:

    grafana.ini:
      server:
        enable_gzip: "true"
      analytics:
        check_for_updates: false
        reporting_enabled: false
      auth.anonymous:
        enabled: true
        org_name: "Main Org."
        org_role: "Viewer"
      unified_alerting:
        enabled: true
      metrics:
        enabled: true

  prometheus:
    prometheusSpec:
      additionalScrapeConfigs:
        ## Monitor external services
        - job_name: 'blackbox'
          # blackbox-exporter path to scrape
          metrics_path: /probe
          static_configs:
            - labels:
                module: http_2xx
            - targets:
                - https://git.crisp.rbro.rbg.cc
              labels:
                managedBy: "externalTeam"
            - targets:
                - https://git.crisp.rbro.rbg.cc
              labels:
                managedBy: "DevOps"
          relabel_configs:
            # 1. Save address in a separate label
            - source_labels: [__address__]
              target_label: __param_target

            # 2. Save module in an module label since __param_module is going to be dropped
            - source_labels: [module]
              target_label: __param_module

            # 3. Save module in an module label since __param_target is going to be dropped
            - source_labels: [__param_target]
              target_label: instance

            # 4. Replace address with an internal blackbox service so scraper is always pointed at blackbox-exporter
            - target_label: __address__
              replacement: prometheus-mgmt-prometheus-blackbox-exporter:9115
            # Ingress annotation for disableing checks - monitoring/exclude: true
            - source_labels: [__meta_kubernetes_ingress_annotation_monitoring_exclude]
              regex: "true"
              action: drop

        - job_name: 'kubernetes-ingresses'
          metrics_path: /probe
          params:
            module: [http_2xx]
          kubernetes_sd_configs:
          - role: ingress
          relabel_configs:
          - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
            regex: (.+);(.+);(.+)
            replacement: ${1}://${2}${3}
            target_label: __param_target
          - target_label: __address__
            replacement: prometheus-mgmt-prometheus-blackbox-exporter:9115
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_ingress_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_ingress_name]
            target_label: name
          # Ingress annotation for disableing checks - monitoring/exclude: true
          - source_labels: [__meta_kubernetes_ingress_annotation_monitoring_exclude]
            regex: "true"
            action: drop

    ingress:
      hosts:
        - prometheus.mgmt.crisp.rbro.rbg.cc

    additionalServiceMonitors:
      - name: "argocd-metrics"
        endpoints:
          - port: metrics
            interval: 30s
        selector:
          matchLabels:
            app.kubernetes.io/name: argocd-metrics
        namespaceSelector:
          any: true
      - name: "argocd-server-metrics"
        endpoints:
          - port: metrics
            interval: 30s
        selector:
          matchLabels:
            app.kubernetes.io/name: argocd-server-metrics
        namespaceSelector:
          any: true
      - name: "argocd-repo-server-metrics"
        endpoints:
          - port: metrics
            interval: 30s
        selector:
          matchLabels:
            app.kubernetes.io/name: argocd-repo-server-metrics
        namespaceSelector:
          any: true
      - name: "rook-ceph-mgr"
        endpoints:
          - interval: 5s
            path: /metrics
            port: http-metrics
        namespaceSelector:
          matchNames:
          - rook-ceph-cluster
        selector:
          matchLabels:
            app: rook-ceph-mgr
            rook_cluster: rook-ceph-cluster
      - name: "csi-metrics"
        endpoints:
        - interval: 5s
          path: /metrics
          port: csi-http-metrics
        - interval: 5s
          path: /metrics
          port: csi-grpc-metrics
        namespaceSelector:
          matchNames:
          - rook-ceph-cluster
        selector:
          matchLabels:
            app: csi-metrics

  alertmanager:
    ingress:
      hosts:
        - alertmanager.mgmt.crisp.rbro.rbg.cc
    config:
      route:
        routes:
        - match:
            job: jenkins-services
          receiver: prometheus-msteams

prometheus-blackbox-exporter:
  enabled: true

  restartPolicy: Always

  kind: Deployment

  podDisruptionBudget: {}
    # maxUnavailable: 0

  ## Enable pod security policy
  pspEnabled: true

  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate

  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  # pullSecrets:
  #   - myRegistrKeySecretName

  ## User to run blackbox-exporter container as
  runAsUser: 1000
  readOnlyRootFilesystem: true
  runAsNonRoot: true

  livenessProbe:
    httpGet:
      path: /health
      port: http

  readinessProbe:
    httpGet:
      path: /health
      port: http

  nodeSelector:
    kubernetes.io/os: linux
    ReservedFor: monitoring

  tolerations:
    - key: "ForMonitoring"
      operator: "Equal"
      value: "true"

  affinity: {}

  secretConfig: false

  config:
    modules:
      http_2xx:
        prober: http
        timeout: 20s
        http:
          follow_redirects: true
          valid_http_versions: ["HTTP/1.1"]
          preferred_ip_protocol: "ip4"
          valid_status_codes:
            - 200
            - 401
            - 403
            - 404
            - 302
          tls_config:
            insecure_skip_verify: true

  extraConfigmapMounts: []
    # - name: crisp.rbro.rbg.cc
    #   mountPath: /etc/secrets/ssl
    #   configMap: crisp.rbro.rbg.cc
    #   readOnly: true
    #   defaultMode: 420

  ## Additional secret mounts
  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.
  extraSecretMounts: []
    # - name: secret-files
    #   mountPath: /etc/secrets
    #   secretName: blackbox-secret-files
    #   readOnly: true
    #   defaultMode: 420

  allowIcmp: false

  resources: {}
    # limits:
    #   memory: 300Mi
    # requests:
    #   memory: 50Mi

  priorityClassName: ""

  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    port: 9115

  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:
    annotations: {}

  ## An Ingress resource can provide name-based virtual hosting and TLS
  ## termination among other things for CouchDB deployments which are accessed
  ## from outside the Kubernetes cluster.
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/

## An Ingress resource can provide name-based virtual hosting and TLS
## termination among other things for CouchDB deployments which are accessed
## from outside the Kubernetes cluster.
## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    className: ""
    labels: {}
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: blackbox.mgmt.crisp.rbro.rbg.cc
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  podAnnotations: {}

  pod:
    labels: {}

  extraArgs: []
  #  --history.limit=1000

  replicas: 1

  serviceMonitor:
    ## If true, a ServiceMonitor CRD is created for a prometheus operator
    ## https://github.com/coreos/prometheus-operator
    ##
    enabled: false

    # Default values that will be used for all ServiceMonitors created by `targets`
    defaults:
      additionalMetricsRelabels: {}
      labels: {}
      interval: 30s
      scrapeTimeout: 30s
      module: http_2xx

    targets:
     - name: essence.crisp.rbro.rbg.cc
       url: https://essence.crisp.rbro.rbg.cc
       labels:
          app: jenkins-operator
       interval: 60s
       scrapeTimeout: 60s
       module: http_2xx
       additionalMetricsRelabels: {}

  ## Custom PrometheusRules to be defined
  ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
  prometheusRule:
    enabled: false
    additionalLabels: {}
    namespace: ""
    rules: []

  ## Network policy for chart
  networkPolicy:
    # Enable network policy and allow access from anywhere
    enabled: false
    # Limit access only from monitoring namespace
    allowMonitoringNamespace: false

  ## dnsPolicy and dnsConfig for Deployments and Daemonsets if you want non-default settings.
  ## These will be passed directly to the PodSpec of same.
  dnsPolicy:
  dnsConfig:
    # nameservers:
    #   - 10.241.200.1
    #   - 10.241.200.2
    #   - 10.241.200.3

promtail:
  enabled: true
  config:
    clients:
      - url: http://prometheus-mgmt-loki-gateway/loki/api/v1/push

loki:
  gateway:
    ingress:
      hosts:
        - host: loki-gateway.mgmt.crisp.rbro.rbg.cc
          paths:
            - path: /
              pathType: Prefix
